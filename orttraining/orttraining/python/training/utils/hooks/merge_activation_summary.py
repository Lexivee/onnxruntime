# -------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License.
# --------------------------------------------------------------------------


"""This file is used to merge convergence debugging summary files.
    It is used to compare activation results between pytorch and ORT.
    Both PyTorch and ORT run result directory are needed, check
    [ORTModule_Convergence_Notes](docs/ORTModule_Convergence_Notes.md) for how to export the results.
"""

import argparse
import logging
import os
import shutil

logger = logging.getLogger(__name__)


def generate_summaries_per_step(args):
    pt_dir = args.pt_dir
    ort_dir = args.ort_dir
    output_dir = args.output_dir

    os.makedirs(output_dir, exist_ok=True)

    # We should use the order.txt generated by pytorch run, that means, we follow the pytorch topo order to compare
    # activation results. Here we assume to get the order.txt from pt_dir/step_0/order.txt
    topo_order_file_path = os.path.join(pt_dir, "step_0", "order.txt")

    def generate_summary_per_step(o_path, d_path, merge_dir_name):
        print(f"Start generating summary per step for {d_path} following typological order in {o_path}")
        order_file = open(o_path)
        tensor_name_in_order = order_file.readlines()
        if os.path.exists(merge_dir_name):
            shutil.rmtree(merge_dir_name)
        os.makedirs(merge_dir_name, exist_ok=True)
        for sub_dir_name in os.listdir(d_path):
            sub_dir_full_path = os.path.join(d_path, sub_dir_name)

            if os.path.isdir(sub_dir_full_path):
                merge_filename_for_sub_dir = os.path.join(merge_dir_name, f"{sub_dir_name}_.txt")
                # Open merge_filename_for_sub_dir in write mode
                with open(merge_filename_for_sub_dir, "w") as outfile:
                    # Iterate through list
                    for filename in tensor_name_in_order:
                        filename = filename.rstrip("\n")
                        full_filename = os.path.join(sub_dir_full_path, filename)

                        if not os.path.exists(full_filename):
                            # Be noted that, some tensor handled in pytorch might be missing in ORT graph
                            # (if the activation is not used by others, which is pruned during export)

                            print(f"tensor {full_filename} not exist")
                            continue

                        # Open each file in read mode
                        with open(full_filename) as infile:
                            # read the data from file1 and
                            # file2 and write it in file3
                            outfile.write(infile.read())

                        # Add '\n' to enter data of file2
                        # from next line
                        outfile.write("\n")

        print(
            f"Finish generating summary per step for {d_path} following typological order in {o_path}, "
            f"merged files are in {os.path.join(d_path, merge_dir_name)}"
        )

    generate_summary_per_step(topo_order_file_path, pt_dir, os.path.join(output_dir, "merge_pt"))
    generate_summary_per_step(topo_order_file_path, ort_dir, os.path.join(output_dir, "merge_ort"))


def parse_arguments():
    """Parse arguments

    Returns:
        Namespace: arguments
    """
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--pt_dir",
        required=True,
        type=str,
        help="Root of input directory of PyTorch run result of activation dump.",
    )

    parser.add_argument(
        "--ort_dir",
        required=True,
        type=str,
        help="Root of input directory of ORTModule run result of activation dump.",
    )

    parser.add_argument(
        "--output_dir",
        required=True,
        type=str,
        help="Root of output directory for generated PyTorch/ORTModule per-step summaries.",
    )

    parser.add_argument(
        "--overwrite",
        required=False,
        action="store_true",
        help="Overwrite exists output files.",
    )
    parser.set_defaults(overwrite=False)

    args = parser.parse_args()
    return args


def main():
    args = parse_arguments()

    if os.path.exists(args.output_dir):
        if args.overwrite:
            import warnings

            warnings.warn(f"Output directory {args.output_dir} already exists, overwrite it.")
            shutil.rmtree(args.output_dir)
        else:
            raise ValueError(
                f"Output directory {args.output_dir} already exists. " "Enable --overwrite to allow overwriting it."
            )

    logger.info("Arguments: %s", str(args))
    generate_summaries_per_step(args)


if __name__ == "__main__":
    main()
