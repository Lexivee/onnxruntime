<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONNX Runtime: onnxruntime::CUDAExecutionProvider Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ONNX Runtime
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="namespaceonnxruntime.html">onnxruntime</a></li><li class="navelem"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html">CUDAExecutionProvider</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classonnxruntime_1_1CUDAExecutionProvider-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">onnxruntime::CUDAExecutionProvider Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="cuda__execution__provider_8h_source.html">cuda_execution_provider.h</a>&gt;</code></p>
<div class="dynheader">
Inheritance diagram for onnxruntime::CUDAExecutionProvider:</div>
<div class="dyncontent">
<div class="center"><img src="classonnxruntime_1_1CUDAExecutionProvider__inherit__graph.png" border="0" usemap="#onnxruntime_1_1CUDAExecutionProvider_inherit__map" alt="Inheritance graph"/></div>
<!-- MAP 0 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<div class="dynheader">
Collaboration diagram for onnxruntime::CUDAExecutionProvider:</div>
<div class="dyncontent">
<div class="center"><img src="classonnxruntime_1_1CUDAExecutionProvider__coll__graph.png" border="0" usemap="#onnxruntime_1_1CUDAExecutionProvider_coll__map" alt="Collaboration graph"/></div>
<!-- MAP 1 -->
<center><span class="legend">[<a href="graph_legend.html">legend</a>]</span></center></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a72cfc3ceddf32a30387296364cc3ea35"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a72cfc3ceddf32a30387296364cc3ea35">CUDAExecutionProvider</a> (const <a class="el" href="structonnxruntime_1_1CUDAExecutionProviderInfo.html">CUDAExecutionProviderInfo</a> &amp;info)</td></tr>
<tr class="separator:a72cfc3ceddf32a30387296364cc3ea35"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98fd8afe88815ad4c423edb8e39f7885"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a98fd8afe88815ad4c423edb8e39f7885">~CUDAExecutionProvider</a> ()</td></tr>
<tr class="separator:a98fd8afe88815ad4c423edb8e39f7885"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01469a525b621ce14a85fcc8187847c4"><td class="memItemLeft" align="right" valign="top"><a class="el" href="namespaceonnxruntime.html#a6cdac724c5dcefded3a63f08dae58fda">AllocatorPtr</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a01469a525b621ce14a85fcc8187847c4">GetAllocator</a> (int id, <a class="el" href="allocator__info_8h.html#add3f8ee3ff93395704abae71c30cab18">ONNXRuntimeMemType</a> mem_type=<a class="el" href="allocator__info_8h.html#add3f8ee3ff93395704abae71c30cab18a232271cbf46c229ed40272a63af7a204">ONNXRuntimeMemTypeDefault</a>) const override</td></tr>
<tr class="separator:a01469a525b621ce14a85fcc8187847c4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aba2225328bd739b5e6ef4be06557985b"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#aba2225328bd739b5e6ef4be06557985b">Type</a> () const override</td></tr>
<tr class="separator:aba2225328bd739b5e6ef4be06557985b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a4f3479126d1191bb1074c4b953b3ef87"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a4f3479126d1191bb1074c4b953b3ef87">Sync</a> () const override</td></tr>
<tr class="separator:a4f3479126d1191bb1074c4b953b3ef87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abf7e482aba687b89fcbd6586271ca753"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#abf7e482aba687b89fcbd6586271ca753">OnRunStart</a> () override</td></tr>
<tr class="separator:abf7e482aba687b89fcbd6586271ca753"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aad4464387bb09d2337e334d5a7325e5d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#aad4464387bb09d2337e334d5a7325e5d">OnRunEnd</a> () override</td></tr>
<tr class="separator:aad4464387bb09d2337e334d5a7325e5d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6f2ec2e4082683b6de03eeb48acbf546"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a6f2ec2e4082683b6de03eeb48acbf546">CopyTensor</a> (const <a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;src, <a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;dst) const override</td></tr>
<tr class="separator:a6f2ec2e4082683b6de03eeb48acbf546"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7238cead30fe69540b3df62e6913d579"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a7238cead30fe69540b3df62e6913d579">CopyTensor</a> (const <a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;src, <a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;dst, int exec_queue_id) const override</td></tr>
<tr class="separator:a7238cead30fe69540b3df62e6913d579"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1cf09f277e0559c0e864fa6b0d39c898"><td class="memItemLeft" align="right" valign="top">const <a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a> *&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a1cf09f277e0559c0e864fa6b0d39c898">GetExecutionHandle</a> () const noexcept override</td></tr>
<tr class="separator:a1cf09f277e0559c0e864fa6b0d39c898"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3f8178414579cf4207dd34afc75438f6"><td class="memItemLeft" align="right" valign="top">cublasHandle_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a3f8178414579cf4207dd34afc75438f6">PerThreadCublasHandle</a> ()</td></tr>
<tr class="separator:a3f8178414579cf4207dd34afc75438f6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9e4e2ca076bb0fa560eac0bd88ab27fa"><td class="memItemLeft" align="right" valign="top">cudnnHandle_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a9e4e2ca076bb0fa560eac0bd88ab27fa">PerThreadCudnnHandle</a> ()</td></tr>
<tr class="separator:a9e4e2ca076bb0fa560eac0bd88ab27fa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac97b455cec41500ac347f375ece13c1e"><td class="memItemLeft" align="right" valign="top">cudaStream_t&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#ac97b455cec41500ac347f375ece13c1e">GetStream</a> (int queue_id) const</td></tr>
<tr class="separator:ac97b455cec41500ac347f375ece13c1e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a76dc7ab7a7a58043697a83cb6c69be2e"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a76dc7ab7a7a58043697a83cb6c69be2e"><td class="memTemplItemLeft" align="right" valign="top">const T *&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a76dc7ab7a7a58043697a83cb6c69be2e">GetConstOnes</a> (<a class="el" href="mlasi_8h.html#a503efbc1c6e50825320ad909366b78ab">size_t</a> count)</td></tr>
<tr class="separator:a76dc7ab7a7a58043697a83cb6c69be2e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a37a6f28d78d81de1c903464b78a8744a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a37a6f28d78d81de1c903464b78a8744a">AddDeferredReleaseCPUPtr</a> (<a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a> *p)</td></tr>
<tr class="separator:a37a6f28d78d81de1c903464b78a8744a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a850dd443cf0b9e0d280fd342ef399696"><td class="memTemplParams" colspan="2">template&lt;typename T &gt; </td></tr>
<tr class="memitem:a850dd443cf0b9e0d280fd342ef399696"><td class="memTemplItemLeft" align="right" valign="top"><a class="el" href="namespaceonnxruntime.html#a323aace024f171700e4b07b299a178e7">IAllocatorUniquePtr</a>&lt; T &gt;&#160;</td><td class="memTemplItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a850dd443cf0b9e0d280fd342ef399696">GetScratchBuffer</a> (<a class="el" href="mlasi_8h.html#a503efbc1c6e50825320ad909366b78ab">size_t</a> count_or_bytes) const</td></tr>
<tr class="separator:a850dd443cf0b9e0d280fd342ef399696"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a771c4dbe04b51b0c019e8b0e4648f61c"><td class="memItemLeft" align="right" valign="top">virtual std::shared_ptr&lt; <a class="el" href="classonnxruntime_1_1KernelRegistry.html">KernelRegistry</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a771c4dbe04b51b0c019e8b0e4648f61c">GetKernelRegistry</a> () const override</td></tr>
<tr class="separator:a771c4dbe04b51b0c019e8b0e4648f61c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1bb04dae34303befc1db6b487dc4c7c5"><td class="memItemLeft" align="right" valign="top">virtual std::vector&lt; std::unique_ptr&lt; <a class="el" href="structonnxruntime_1_1ComputationCapacity.html">ComputationCapacity</a> &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1CUDAExecutionProvider.html#a1bb04dae34303befc1db6b487dc4c7c5">GetCapability</a> (const <a class="el" href="classonnxruntime_1_1GraphViewer.html">onnxruntime::GraphViewer</a> &amp;graph, const std::vector&lt; const <a class="el" href="classonnxruntime_1_1KernelRegistry.html">KernelRegistry</a> *&gt; &amp;kernel_registries) const override</td></tr>
<tr class="separator:a1bb04dae34303befc1db6b487dc4c7c5"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="inherit_header pub_methods_classonnxruntime_1_1IExecutionProvider"><td colspan="2" onclick="javascript:toggleInherit('pub_methods_classonnxruntime_1_1IExecutionProvider')"><img src="closed.png" alt="-"/>&#160;Public Member Functions inherited from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html">onnxruntime::IExecutionProvider</a></td></tr>
<tr class="memitem:a996806d27429056e13184d5ff4590d24 inherit pub_methods_classonnxruntime_1_1IExecutionProvider"><td class="memItemLeft" align="right" valign="top">virtual&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a996806d27429056e13184d5ff4590d24">~IExecutionProvider</a> ()=default</td></tr>
<tr class="separator:a996806d27429056e13184d5ff4590d24 inherit pub_methods_classonnxruntime_1_1IExecutionProvider"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a25d94e7e7bd716f636a7f64802376751 inherit pub_methods_classonnxruntime_1_1IExecutionProvider"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="namespaceonnxruntime.html#a6cdac724c5dcefded3a63f08dae58fda">AllocatorPtr</a> &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a25d94e7e7bd716f636a7f64802376751">GetAllocatorMap</a> () const</td></tr>
<tr class="separator:a25d94e7e7bd716f636a7f64802376751 inherit pub_methods_classonnxruntime_1_1IExecutionProvider"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a625943e29574b9876f3d7c34e3fe882e inherit pub_methods_classonnxruntime_1_1IExecutionProvider"><td class="memItemLeft" align="right" valign="top"><a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a625943e29574b9876f3d7c34e3fe882e">InsertAllocator</a> (<a class="el" href="namespaceonnxruntime.html#a6cdac724c5dcefded3a63f08dae58fda">AllocatorPtr</a> allocator)</td></tr>
<tr class="separator:a625943e29574b9876f3d7c34e3fe882e inherit pub_methods_classonnxruntime_1_1IExecutionProvider"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a id="a72cfc3ceddf32a30387296364cc3ea35"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a72cfc3ceddf32a30387296364cc3ea35">&#9670;&nbsp;</a></span>CUDAExecutionProvider()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime::CUDAExecutionProvider::CUDAExecutionProvider </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structonnxruntime_1_1CUDAExecutionProviderInfo.html">CUDAExecutionProviderInfo</a> &amp;&#160;</td>
          <td class="paramname"><em>info</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">explicit</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a98fd8afe88815ad4c423edb8e39f7885"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98fd8afe88815ad4c423edb8e39f7885">&#9670;&nbsp;</a></span>~CUDAExecutionProvider()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">onnxruntime::CUDAExecutionProvider::~CUDAExecutionProvider </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a id="a37a6f28d78d81de1c903464b78a8744a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37a6f28d78d81de1c903464b78a8744a">&#9670;&nbsp;</a></span>AddDeferredReleaseCPUPtr()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a> onnxruntime::CUDAExecutionProvider::AddDeferredReleaseCPUPtr </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a> *&#160;</td>
          <td class="paramname"><em>p</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

</div>
</div>
<a id="a6f2ec2e4082683b6de03eeb48acbf546"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a6f2ec2e4082683b6de03eeb48acbf546">&#9670;&nbsp;</a></span>CopyTensor() <span class="overload">[1/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a> onnxruntime::CUDAExecutionProvider::CopyTensor </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>src</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>dst</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Copy tensor between execution providers </p>

<p>Implements <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a2b9bb47c0d2d72598ceb381688adfe26">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a7238cead30fe69540b3df62e6913d579"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7238cead30fe69540b3df62e6913d579">&#9670;&nbsp;</a></span>CopyTensor() <span class="overload">[2/2]</span></h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a> onnxruntime::CUDAExecutionProvider::CopyTensor </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>src</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="classonnxruntime_1_1Tensor.html">Tensor</a> &amp;&#160;</td>
          <td class="paramname"><em>dst</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>exec_queue_id</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Copy tensor between execution providers on specified exec queue </p>

<p>Reimplemented from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#ac72d136c6a46bb4f33c9a877e01cccaa">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a01469a525b621ce14a85fcc8187847c4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01469a525b621ce14a85fcc8187847c4">&#9670;&nbsp;</a></span>GetAllocator()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceonnxruntime.html#a6cdac724c5dcefded3a63f08dae58fda">AllocatorPtr</a> onnxruntime::CUDAExecutionProvider::GetAllocator </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>id</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="allocator__info_8h.html#add3f8ee3ff93395704abae71c30cab18">ONNXRuntimeMemType</a>&#160;</td>
          <td class="paramname"><em>mem_type</em> = <code><a class="el" href="allocator__info_8h.html#add3f8ee3ff93395704abae71c30cab18a232271cbf46c229ed40272a63af7a204">ONNXRuntimeMemTypeDefault</a></code>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Get allocator with specified MemType </p>

<p>Reimplemented from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#ab4911f5441a3bd940b0384bc5a334b92">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a1bb04dae34303befc1db6b487dc4c7c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1bb04dae34303befc1db6b487dc4c7c5">&#9670;&nbsp;</a></span>GetCapability()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; std::unique_ptr&lt; <a class="el" href="structonnxruntime_1_1ComputationCapacity.html">ComputationCapacity</a> &gt; &gt; onnxruntime::CUDAExecutionProvider::GetCapability </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classonnxruntime_1_1GraphViewer.html">onnxruntime::GraphViewer</a> &amp;&#160;</td>
          <td class="paramname"><em>graph_viewer</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::vector&lt; const <a class="el" href="classonnxruntime_1_1KernelRegistry.html">KernelRegistry</a> *&gt; &amp;&#160;</td>
          <td class="paramname"><em>kernel_registries</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Get execution provider's capability for the specified &lt;graph&gt;. Return a bunch of IndexedSubGraphs &lt;*this&gt; execution provider can run if the sub-graph contains only one node or can fuse to run if the sub-graph contains more than one node. The node indexes contained in sub-graphs may have overlap, and it's ONNXRuntime's responsibility to do the partition and decide whether a node will be assigned to &lt;*this&gt; execution provider. </p>

<p>Reimplemented from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a6f17ba64b2355b26293a4cfc3fac376f">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a76dc7ab7a7a58043697a83cb6c69be2e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a76dc7ab7a7a58043697a83cb6c69be2e">&#9670;&nbsp;</a></span>GetConstOnes()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const T* onnxruntime::CUDAExecutionProvider::GetConstOnes </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="mlasi_8h.html#a503efbc1c6e50825320ad909366b78ab">size_t</a>&#160;</td>
          <td class="paramname"><em>count</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a1cf09f277e0559c0e864fa6b0d39c898"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cf09f277e0559c0e864fa6b0d39c898">&#9670;&nbsp;</a></span>GetExecutionHandle()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">const <a class="el" href="mlasi_8h.html#a88f941d423cb2a819b70a1358982b1a6">void</a>* onnxruntime::CUDAExecutionProvider::GetExecutionHandle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">virtual</span><span class="mlabel">noexcept</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Returns an opaque handle whose exact type varies based on the provider and is interpreted accordingly by the corresponding kernel implementation. For Direct3D operator kernels, this may return an IUnknown supporting QueryInterface to ID3D12GraphicsCommandList1. </p>

<p>Implements <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#aebaeab04945539bc5db5942b63684ccb">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a771c4dbe04b51b0c019e8b0e4648f61c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a771c4dbe04b51b0c019e8b0e4648f61c">&#9670;&nbsp;</a></span>GetKernelRegistry()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::shared_ptr&lt; <a class="el" href="classonnxruntime_1_1KernelRegistry.html">KernelRegistry</a> &gt; onnxruntime::CUDAExecutionProvider::GetKernelRegistry </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Get kernel registry per execution provider type. The <a class="el" href="classonnxruntime_1_1KernelRegistry.html">KernelRegistry</a> share pointer returned is shared across sessions.</p>
<p>NOTE: this is a tricky but final solution to achieve following goals,</p><ol type="1">
<li>The execution provider type based kernel registry should be shared across sessions. Only one copy of this kind of kernel registry exists in ONNXRuntime with multiple sessions/models.</li>
<li>Adding an execution provider into ONNXRuntime does not need to touch ONNXRuntime frameowrk/session code.</li>
<li>onnxruntime runtime (framework/session) does not depend on any specific execution provider lib. </li>
</ol>

<p>Implements <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a83caf9a8da9fcbc4e7fdc891055d664d">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a850dd443cf0b9e0d280fd342ef399696"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a850dd443cf0b9e0d280fd342ef399696">&#9670;&nbsp;</a></span>GetScratchBuffer()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T &gt; </div>
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="namespaceonnxruntime.html#a323aace024f171700e4b07b299a178e7">IAllocatorUniquePtr</a>&lt;T&gt; onnxruntime::CUDAExecutionProvider::GetScratchBuffer </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="mlasi_8h.html#a503efbc1c6e50825320ad909366b78ab">size_t</a>&#160;</td>
          <td class="paramname"><em>count_or_bytes</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="ac97b455cec41500ac347f375ece13c1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac97b455cec41500ac347f375ece13c1e">&#9670;&nbsp;</a></span>GetStream()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">cudaStream_t onnxruntime::CUDAExecutionProvider::GetStream </td>
          <td>(</td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>queue_id</em></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="aad4464387bb09d2337e334d5a7325e5d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aad4464387bb09d2337e334d5a7325e5d">&#9670;&nbsp;</a></span>OnRunEnd()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a> onnxruntime::CUDAExecutionProvider::OnRunEnd </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Called when <a class="el" href="classonnxruntime_1_1InferenceSession.html#a90aa8b5fdc2638c4d2c45afc9c3ed222">InferenceSession::Run</a> ended NOTE that due to async execution in provider, the actual work of this Run may not be finished on device This function should be regarded as the point that all commands of current Run has been submmited by CPU </p>

<p>Reimplemented from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a2a4b49018ff2509a01c1dd73b5cbb811">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="abf7e482aba687b89fcbd6586271ca753"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abf7e482aba687b89fcbd6586271ca753">&#9670;&nbsp;</a></span>OnRunStart()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a> onnxruntime::CUDAExecutionProvider::OnRunStart </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Called when <a class="el" href="classonnxruntime_1_1InferenceSession.html#a90aa8b5fdc2638c4d2c45afc9c3ed222">InferenceSession::Run</a> started NOTE that due to async execution in provider, the actual work of previous Run may not be finished on device This function should be regarded as the point after which a new Run would start to submit commands from CPU </p>

<p>Reimplemented from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a0d724b727c4518125b5b154b481bccb3">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="a3f8178414579cf4207dd34afc75438f6"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3f8178414579cf4207dd34afc75438f6">&#9670;&nbsp;</a></span>PerThreadCublasHandle()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">cublasHandle_t onnxruntime::CUDAExecutionProvider::PerThreadCublasHandle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a9e4e2ca076bb0fa560eac0bd88ab27fa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9e4e2ca076bb0fa560eac0bd88ab27fa">&#9670;&nbsp;</a></span>PerThreadCudnnHandle()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">cudnnHandle_t onnxruntime::CUDAExecutionProvider::PerThreadCudnnHandle </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

</div>
</div>
<a id="a4f3479126d1191bb1074c4b953b3ef87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4f3479126d1191bb1074c4b953b3ef87">&#9670;&nbsp;</a></span>Sync()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classonnxruntime_1_1common_1_1Status.html">Status</a> onnxruntime::CUDAExecutionProvider::Sync </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Blocks until the device has completed all preceding requested tasks. Currently this is primarily used by the <a class="el" href="classonnxruntime_1_1IOBinding.html">IOBinding</a> object to ensure that all inputs have been copied to the device before execution begins. </p>

<p>Reimplemented from <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a3657d5ed274547507a7b99d466fa13ef">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<a id="aba2225328bd739b5e6ef4be06557985b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aba2225328bd739b5e6ef4be06557985b">&#9670;&nbsp;</a></span>Type()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string onnxruntime::CUDAExecutionProvider::Type </td>
          <td>(</td>
          <td class="paramname"></td><td>)</td>
          <td> const</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">override</span><span class="mlabel">virtual</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="section return"><dt>Returns</dt><dd>type of the execution provider; should match that set in the node through the SetExecutionProvider API. Example valid return values are: kCpuExecutionProvider, kCudaExecutionProvider </dd></dl>

<p>Implements <a class="el" href="classonnxruntime_1_1IExecutionProvider.html#a6bfeb7af172299bcc6083a418b01fac1">onnxruntime::IExecutionProvider</a>.</p>

</div>
</div>
<hr/>The documentation for this class was generated from the following files:<ul>
<li>onnxruntime/onnxruntime/core/providers/cuda/<a class="el" href="cuda__execution__provider_8h_source.html">cuda_execution_provider.h</a></li>
<li>onnxruntime/onnxruntime/core/providers/cuda/<a class="el" href="cuda__execution__provider_8cc.html">cuda_execution_provider.cc</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
