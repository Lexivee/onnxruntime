<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.14"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ONNX Runtime: onnxruntime/onnxruntime/core/providers/cuda/math/binary_elementwise_ops.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ONNX Runtime
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.14 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><a class="el" href="dir_e3b9a701244be82c687fe9b0a9acac94.html">onnxruntime</a></li><li class="navelem"><a class="el" href="dir_975c6b7dfd8e9a3052170d7139ee98b5.html">onnxruntime</a></li><li class="navelem"><a class="el" href="dir_d53f99a49d07d97f83b643cb8d6238c5.html">core</a></li><li class="navelem"><a class="el" href="dir_56f632a99c2e8c2266dce49f04e40288.html">providers</a></li><li class="navelem"><a class="el" href="dir_893aee19ddfc3e61cc87531e2d88f525.html">cuda</a></li><li class="navelem"><a class="el" href="dir_609afc67b08be54db96cf2542a798d92.html">math</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">binary_elementwise_ops.h</div>  </div>
</div><!--header-->
<div class="contents">
<a href="binary__elementwise__ops_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a name="l00001"></a><span class="lineno">    1</span>&#160;<span class="comment">// Copyright (c) Microsoft Corporation. All rights reserved.</span></div><div class="line"><a name="l00002"></a><span class="lineno">    2</span>&#160;<span class="comment">// Licensed under the MIT License.</span></div><div class="line"><a name="l00003"></a><span class="lineno">    3</span>&#160;</div><div class="line"><a name="l00004"></a><span class="lineno">    4</span>&#160;<span class="preprocessor">#pragma once</span></div><div class="line"><a name="l00005"></a><span class="lineno">    5</span>&#160;</div><div class="line"><a name="l00006"></a><span class="lineno">    6</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="cuda__common_8h.html">core/providers/cuda/cuda_common.h</a>&quot;</span></div><div class="line"><a name="l00007"></a><span class="lineno">    7</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="fast__divmod_8h.html">core/providers/cuda/shared_inc/fast_divmod.h</a>&quot;</span></div><div class="line"><a name="l00008"></a><span class="lineno">    8</span>&#160;<span class="preprocessor">#include &quot;<a class="code" href="providers_2cpu_2tensor_2utils_8h.html">core/providers/cpu/tensor/utils.h</a>&quot;</span></div><div class="line"><a name="l00009"></a><span class="lineno">    9</span>&#160;</div><div class="line"><a name="l00010"></a><span class="lineno">   10</span>&#160;<span class="keyword">namespace </span><a class="code" href="namespaceonnxruntime.html">onnxruntime</a> {</div><div class="line"><a name="l00011"></a><span class="lineno">   11</span>&#160;<span class="keyword">namespace </span>cuda {</div><div class="line"><a name="l00012"></a><span class="lineno">   12</span>&#160;</div><div class="line"><a name="l00013"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html">   13</a></span>&#160;<span class="keyword">struct </span><a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html">BinaryElementwisePreparation</a> {</div><div class="line"><a name="l00014"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad82404e3c1e95ec44efddff36e8e886a">   14</a></span>&#160;  <span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1Tensor.html">Tensor</a>* <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad82404e3c1e95ec44efddff36e8e886a">lhs_tensor</a> = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00015"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a30db30553236d3694eb6442c2af7edb4">   15</a></span>&#160;  <span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1Tensor.html">Tensor</a>* <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a30db30553236d3694eb6442c2af7edb4">rhs_tensor</a> = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00016"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a8e5baa8a6c92e84c17e3e040ca9acdd2">   16</a></span>&#160;  <a class="code" href="classonnxruntime_1_1Tensor.html">Tensor</a>* <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a8e5baa8a6c92e84c17e3e040ca9acdd2">output_tensor</a> = <span class="keyword">nullptr</span>;</div><div class="line"><a name="l00017"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">   17</a></span>&#160;  <span class="keywordtype">size_t</span> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">output_rank_or_simple_broadcast</a> = 0;               <span class="comment">// for no_broadcast|left_scalar|right_scalar cases, output_rank uses SimpleBroadcast enums</span></div><div class="line"><a name="l00018"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">   18</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html">CudaKernel::CudaAsyncBuffer&lt;int64_t&gt;</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">lhs_padded_strides</a>;  <span class="comment">// for lhs shape == output shape, this is nullptr</span></div><div class="line"><a name="l00019"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">   19</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html">CudaKernel::CudaAsyncBuffer&lt;int64_t&gt;</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">rhs_padded_strides</a>;  <span class="comment">// for rhs shape == output shape, this is nullptr</span></div><div class="line"><a name="l00020"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">   20</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html">CudaKernel::CudaAsyncBuffer&lt;fast_divmod&gt;</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">fdm_output_strides</a>;</div><div class="line"><a name="l00021"></a><span class="lineno">   21</span>&#160;</div><div class="line"><a name="l00022"></a><span class="lineno">   22</span>&#160;  <span class="comment">// these are for RightPerChannel case</span></div><div class="line"><a name="l00023"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#abac17f92f3658f4b478f2f534ce21d4f">   23</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1fast__divmod.html">fast_divmod</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#abac17f92f3658f4b478f2f534ce21d4f">fdm_H</a>;</div><div class="line"><a name="l00024"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ac07a5b9eca61fcc7295038038d306cda">   24</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1fast__divmod.html">fast_divmod</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ac07a5b9eca61fcc7295038038d306cda">fdm_C</a>;</div><div class="line"><a name="l00025"></a><span class="lineno">   25</span>&#160;</div><div class="line"><a name="l00026"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a36f2903469519a3db28a5138e610d2a0">   26</a></span>&#160;  <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a36f2903469519a3db28a5138e610d2a0">BinaryElementwisePreparation</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel.html">CudaKernel</a>* op_kernel) : <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">lhs_padded_strides</a>(op_kernel),</div><div class="line"><a name="l00027"></a><span class="lineno">   27</span>&#160;                                                              <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">rhs_padded_strides</a>(op_kernel),</div><div class="line"><a name="l00028"></a><span class="lineno">   28</span>&#160;                                                              <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">fdm_output_strides</a>(op_kernel) {}</div><div class="line"><a name="l00029"></a><span class="lineno">   29</span>&#160;</div><div class="line"><a name="l00030"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae8057fc5747b8c08a40df19422ca41b0">   30</a></span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae8057fc5747b8c08a40df19422ca41b0">CopyToGpu</a>() {</div><div class="line"><a name="l00031"></a><span class="lineno">   31</span>&#160;    <a class="code" href="include_2onnxruntime_2core_2common_2common_8h.html#a4488572bf87ef9ee844a9aafbc35d8e4">ONNXRUNTIME_RETURN_IF_ERROR</a>(<a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">lhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#ab0d0133fc7d6d9ca6cdd01b7ea7db54d">CopyToGpu</a>());</div><div class="line"><a name="l00032"></a><span class="lineno">   32</span>&#160;    <a class="code" href="include_2onnxruntime_2core_2common_2common_8h.html#a4488572bf87ef9ee844a9aafbc35d8e4">ONNXRUNTIME_RETURN_IF_ERROR</a>(<a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">rhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#ab0d0133fc7d6d9ca6cdd01b7ea7db54d">CopyToGpu</a>());</div><div class="line"><a name="l00033"></a><span class="lineno">   33</span>&#160;    <a class="code" href="include_2onnxruntime_2core_2common_2common_8h.html#a4488572bf87ef9ee844a9aafbc35d8e4">ONNXRUNTIME_RETURN_IF_ERROR</a>(<a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">fdm_output_strides</a>.CopyToGpu());</div><div class="line"><a name="l00034"></a><span class="lineno">   34</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classonnxruntime_1_1common_1_1Status.html#aa38cc1876df38fa258f7ce916cc8cdb7">Status::OK</a>();</div><div class="line"><a name="l00035"></a><span class="lineno">   35</span>&#160;  }</div><div class="line"><a name="l00036"></a><span class="lineno">   36</span>&#160;</div><div class="line"><a name="l00037"></a><span class="lineno"><a class="line" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#aa0b44414b24d61109e896fb3817c4142">   37</a></span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#aa0b44414b24d61109e896fb3817c4142">BinaryElementwiseBroadcastPrepareHelper</a>(<span class="keywordtype">int</span> device_id, <span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1TensorShape.html">TensorShape</a>&amp; lhs_shape,</div><div class="line"><a name="l00038"></a><span class="lineno">   38</span>&#160;                                                 <span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1TensorShape.html">TensorShape</a>&amp; rhs_shape,</div><div class="line"><a name="l00039"></a><span class="lineno">   39</span>&#160;                                                 <span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1TensorShape.html">TensorShape</a>&amp; output_shape) {</div><div class="line"><a name="l00040"></a><span class="lineno">   40</span>&#160;    <span class="keywordtype">size_t</span> lhs_rank = lhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#af9e40196654d3d161544789f61415c53">NumDimensions</a>();</div><div class="line"><a name="l00041"></a><span class="lineno">   41</span>&#160;    <span class="keywordtype">size_t</span> rhs_rank = rhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#af9e40196654d3d161544789f61415c53">NumDimensions</a>();</div><div class="line"><a name="l00042"></a><span class="lineno">   42</span>&#160;    <span class="keywordtype">size_t</span> out_rank = std::max(lhs_rank, rhs_rank);</div><div class="line"><a name="l00043"></a><span class="lineno">   43</span>&#160;</div><div class="line"><a name="l00044"></a><span class="lineno">   44</span>&#160;    <span class="comment">// early return when shapes match</span></div><div class="line"><a name="l00045"></a><span class="lineno">   45</span>&#160;    <span class="keywordflow">if</span> (lhs_shape == rhs_shape) {</div><div class="line"><a name="l00046"></a><span class="lineno">   46</span>&#160;      <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">output_rank_or_simple_broadcast</a> = <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(<a class="code" href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920a60212413510a410bf5192f109ecc4815">SimpleBroadcast::NoBroadcast</a>);</div><div class="line"><a name="l00047"></a><span class="lineno">   47</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classonnxruntime_1_1common_1_1Status.html#aa38cc1876df38fa258f7ce916cc8cdb7">Status::OK</a>();</div><div class="line"><a name="l00048"></a><span class="lineno">   48</span>&#160;    }</div><div class="line"><a name="l00049"></a><span class="lineno">   49</span>&#160;</div><div class="line"><a name="l00050"></a><span class="lineno">   50</span>&#160;    <span class="comment">// early return if one operand is scalar</span></div><div class="line"><a name="l00051"></a><span class="lineno">   51</span>&#160;    <span class="keywordflow">if</span> (lhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a01f6e6fbc270702141c4c45573667cd5">Size</a>() &lt;= 1 || rhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a01f6e6fbc270702141c4c45573667cd5">Size</a>() &lt;= 1) {</div><div class="line"><a name="l00052"></a><span class="lineno">   52</span>&#160;      <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">output_rank_or_simple_broadcast</a> = <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(lhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a01f6e6fbc270702141c4c45573667cd5">Size</a>() &lt;= 1 ? <a class="code" href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920a2121638796bb7e7f58ffecfb894c7135">SimpleBroadcast::LeftScalar</a> : <a class="code" href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920ad5cf49141f858c55da2682a66aa8dde6">SimpleBroadcast::RightScalar</a>);</div><div class="line"><a name="l00053"></a><span class="lineno">   53</span>&#160;      <span class="keywordflow">return</span> <a class="code" href="classonnxruntime_1_1common_1_1Status.html#aa38cc1876df38fa258f7ce916cc8cdb7">Status::OK</a>();</div><div class="line"><a name="l00054"></a><span class="lineno">   54</span>&#160;    }</div><div class="line"><a name="l00055"></a><span class="lineno">   55</span>&#160;</div><div class="line"><a name="l00056"></a><span class="lineno">   56</span>&#160;    <span class="comment">// special case for lhs(N,C,H) and rhs (C,1) which is used in conv bias</span></div><div class="line"><a name="l00057"></a><span class="lineno">   57</span>&#160;    <span class="comment">// when N == 1: out[id] = op(lhs[id], rhs[id / H])</span></div><div class="line"><a name="l00058"></a><span class="lineno">   58</span>&#160;    <span class="comment">// When N &gt; 1:  out[id] = op(lhs[id], rhs[id / H % C])</span></div><div class="line"><a name="l00059"></a><span class="lineno">   59</span>&#160;    <span class="keywordflow">if</span> (lhs_shape == output_shape) {</div><div class="line"><a name="l00060"></a><span class="lineno">   60</span>&#160;      <span class="keyword">const</span> <span class="keyword">auto</span>&amp; rhs_dims = rhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a37834c200e4b93c78a836db93d9aaa5a">GetDims</a>();</div><div class="line"><a name="l00061"></a><span class="lineno">   61</span>&#160;      int64_t <a class="code" href="mlasi_8h.html#a5693f8b3559ce97985de5239fdcf6006">C</a>;</div><div class="line"><a name="l00062"></a><span class="lineno">   62</span>&#160;      <span class="keywordflow">if</span> (1 == std::count_if(rhs_dims.begin(), rhs_dims.end(), [&amp;<a class="code" href="mlasi_8h.html#a5693f8b3559ce97985de5239fdcf6006">C</a>](int64_t dim) { <span class="keywordflow">if</span> (dim &gt; 1) <a class="code" href="mlasi_8h.html#a5693f8b3559ce97985de5239fdcf6006">C</a> = dim; <span class="keywordflow">return</span> (dim &gt; 1); })) {</div><div class="line"><a name="l00063"></a><span class="lineno">   63</span>&#160;        <span class="keyword">auto</span> dim_C = std::find(rhs_dims.begin(), rhs_dims.end(), <a class="code" href="mlasi_8h.html#a5693f8b3559ce97985de5239fdcf6006">C</a>) - rhs_dims.begin() + output_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#af9e40196654d3d161544789f61415c53">NumDimensions</a>() - rhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#af9e40196654d3d161544789f61415c53">NumDimensions</a>();</div><div class="line"><a name="l00064"></a><span class="lineno">   64</span>&#160;        int64_t N = output_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#af322918934d44918346fe19526f52897">SizeToDimension</a>(dim_C);</div><div class="line"><a name="l00065"></a><span class="lineno">   65</span>&#160;        int64_t H = (dim_C &lt; out_rank - 1 ? output_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a4a084e4fe8348af11cf8cf1d22c4800d">SizeFromDimension</a>(dim_C + 1) : 1);</div><div class="line"><a name="l00066"></a><span class="lineno">   66</span>&#160;</div><div class="line"><a name="l00067"></a><span class="lineno">   67</span>&#160;        std::vector&lt;int64_t&gt; new_output_dims;</div><div class="line"><a name="l00068"></a><span class="lineno">   68</span>&#160;        <span class="keywordflow">if</span> (N == 1) {</div><div class="line"><a name="l00069"></a><span class="lineno">   69</span>&#160;          <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">output_rank_or_simple_broadcast</a> = <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(<a class="code" href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920af3c8c9fc27b1c282146c15e980adf190">SimpleBroadcast::RightPerChannelBatch1</a>);</div><div class="line"><a name="l00070"></a><span class="lineno">   70</span>&#160;          <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#abac17f92f3658f4b478f2f534ce21d4f">fdm_H</a> = <a class="code" href="classonnxruntime_1_1cuda_1_1fast__divmod.html">fast_divmod</a>(gsl::narrow_cast&lt;int&gt;(H));</div><div class="line"><a name="l00071"></a><span class="lineno">   71</span>&#160;        } <span class="keywordflow">else</span> {</div><div class="line"><a name="l00072"></a><span class="lineno">   72</span>&#160;          <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">output_rank_or_simple_broadcast</a> = <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>(<a class="code" href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920ab907e3ea1ad58d2a08b02de5e8a27131">SimpleBroadcast::RightPerChannelBatchN</a>);</div><div class="line"><a name="l00073"></a><span class="lineno">   73</span>&#160;          <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#abac17f92f3658f4b478f2f534ce21d4f">fdm_H</a> = <a class="code" href="classonnxruntime_1_1cuda_1_1fast__divmod.html">fast_divmod</a>(gsl::narrow_cast&lt;int&gt;(H));</div><div class="line"><a name="l00074"></a><span class="lineno">   74</span>&#160;          <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ac07a5b9eca61fcc7295038038d306cda">fdm_C</a> = <a class="code" href="classonnxruntime_1_1cuda_1_1fast__divmod.html">fast_divmod</a>(gsl::narrow_cast&lt;int&gt;(<a class="code" href="mlasi_8h.html#a5693f8b3559ce97985de5239fdcf6006">C</a>));</div><div class="line"><a name="l00075"></a><span class="lineno">   75</span>&#160;        }</div><div class="line"><a name="l00076"></a><span class="lineno">   76</span>&#160;        <span class="keywordflow">return</span> <a class="code" href="classonnxruntime_1_1common_1_1Status.html#aa38cc1876df38fa258f7ce916cc8cdb7">Status::OK</a>();</div><div class="line"><a name="l00077"></a><span class="lineno">   77</span>&#160;      }</div><div class="line"><a name="l00078"></a><span class="lineno">   78</span>&#160;    }</div><div class="line"><a name="l00079"></a><span class="lineno">   79</span>&#160;</div><div class="line"><a name="l00080"></a><span class="lineno">   80</span>&#160;    <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">output_rank_or_simple_broadcast</a> = out_rank;</div><div class="line"><a name="l00081"></a><span class="lineno">   81</span>&#160;</div><div class="line"><a name="l00082"></a><span class="lineno">   82</span>&#160;    <span class="keywordflow">if</span> (lhs_shape != output_shape) {</div><div class="line"><a name="l00083"></a><span class="lineno">   83</span>&#160;      <span class="comment">// compute strides with 1 more dim than out_rank, and use strides[0] == strides[1]</span></div><div class="line"><a name="l00084"></a><span class="lineno">   84</span>&#160;      <span class="comment">// to decide if dim0 needs broadcast</span></div><div class="line"><a name="l00085"></a><span class="lineno">   85</span>&#160;      <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">lhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a1987dd49b4f3fc47fe8c780ce232654d">AllocCpuPtr</a>(device_id, out_rank + 1);</div><div class="line"><a name="l00086"></a><span class="lineno">   86</span>&#160;      <a class="code" href="include_2onnxruntime_2core_2common_2common_8h.html#ad131e4f1ee9a9dcb3fe224c5eea0ffaf">ONNXRUNTIME_RETURN_IF_NOT</a>(<a class="code" href="structonnxruntime_1_1TensorPitches.html#a406e89348dd83badf0483bfd9df832a7">TensorPitches::Calculate</a>(<a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">lhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a1719d3e411ca256e4b57898795ef58ca">CpuSpan</a>(), lhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a37834c200e4b93c78a836db93d9aaa5a">GetDims</a>()));</div><div class="line"><a name="l00087"></a><span class="lineno">   87</span>&#160;      <span class="keywordflow">if</span> (lhs_shape[0] &gt; 1 &amp;&amp; lhs_rank == out_rank)</div><div class="line"><a name="l00088"></a><span class="lineno">   88</span>&#160;        <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">lhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a5d0e11c43d1ab7929d7b2f32bc24871c">CpuPtr</a>()[0] = 0;</div><div class="line"><a name="l00089"></a><span class="lineno">   89</span>&#160;    }</div><div class="line"><a name="l00090"></a><span class="lineno">   90</span>&#160;</div><div class="line"><a name="l00091"></a><span class="lineno">   91</span>&#160;    <span class="keywordflow">if</span> (rhs_shape != output_shape) {</div><div class="line"><a name="l00092"></a><span class="lineno">   92</span>&#160;      <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">rhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a1987dd49b4f3fc47fe8c780ce232654d">AllocCpuPtr</a>(device_id, out_rank + 1);</div><div class="line"><a name="l00093"></a><span class="lineno">   93</span>&#160;      <a class="code" href="include_2onnxruntime_2core_2common_2common_8h.html#ad131e4f1ee9a9dcb3fe224c5eea0ffaf">ONNXRUNTIME_RETURN_IF_NOT</a>(<a class="code" href="structonnxruntime_1_1TensorPitches.html#a406e89348dd83badf0483bfd9df832a7">TensorPitches::Calculate</a>(<a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">rhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a1719d3e411ca256e4b57898795ef58ca">CpuSpan</a>(), rhs_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a37834c200e4b93c78a836db93d9aaa5a">GetDims</a>()));</div><div class="line"><a name="l00094"></a><span class="lineno">   94</span>&#160;      <span class="keywordflow">if</span> (rhs_shape[0] &gt; 1 &amp;&amp; rhs_rank == out_rank)</div><div class="line"><a name="l00095"></a><span class="lineno">   95</span>&#160;        <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">rhs_padded_strides</a>.<a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a5d0e11c43d1ab7929d7b2f32bc24871c">CpuPtr</a>()[0] = 0;</div><div class="line"><a name="l00096"></a><span class="lineno">   96</span>&#160;    }</div><div class="line"><a name="l00097"></a><span class="lineno">   97</span>&#160;</div><div class="line"><a name="l00098"></a><span class="lineno">   98</span>&#160;    <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">fdm_output_strides</a>.AllocCpuPtr(device_id, out_rank);</div><div class="line"><a name="l00099"></a><span class="lineno">   99</span>&#160;    <a class="code" href="include_2onnxruntime_2core_2common_2common_8h.html#ad131e4f1ee9a9dcb3fe224c5eea0ffaf">ONNXRUNTIME_RETURN_IF_NOT</a>(<a class="code" href="namespaceonnxruntime_1_1cuda.html#ad1695824538013a3c72989f1a78ce5ec">CalculateFdmStrides</a>(<a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">fdm_output_strides</a>.CpuSpan(), output_shape.<a class="code" href="classonnxruntime_1_1TensorShape.html#a37834c200e4b93c78a836db93d9aaa5a">GetDims</a>()));</div><div class="line"><a name="l00100"></a><span class="lineno">  100</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classonnxruntime_1_1common_1_1Status.html#aa38cc1876df38fa258f7ce916cc8cdb7">Status::OK</a>();</div><div class="line"><a name="l00101"></a><span class="lineno">  101</span>&#160;  }</div><div class="line"><a name="l00102"></a><span class="lineno">  102</span>&#160;};</div><div class="line"><a name="l00103"></a><span class="lineno">  103</span>&#160;</div><div class="line"><a name="l00104"></a><span class="lineno">  104</span>&#160;</div><div class="line"><a name="l00105"></a><span class="lineno">  105</span>&#160;<span class="comment">// trait classes to indicate if the kernel supports broadcast</span></div><div class="line"><a name="l00106"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1ShouldBroadcast.html">  106</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1ShouldBroadcast.html">ShouldBroadcast</a> {</div><div class="line"><a name="l00107"></a><span class="lineno">  107</span>&#160;};</div><div class="line"><a name="l00108"></a><span class="lineno">  108</span>&#160;</div><div class="line"><a name="l00109"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1ShouldNotBroadcast.html">  109</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1ShouldNotBroadcast.html">ShouldNotBroadcast</a> {</div><div class="line"><a name="l00110"></a><span class="lineno">  110</span>&#160;};</div><div class="line"><a name="l00111"></a><span class="lineno">  111</span>&#160;</div><div class="line"><a name="l00112"></a><span class="lineno">  112</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> BroadcastTrait&gt;</div><div class="line"><a name="l00113"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">  113</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a> : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel.html">CudaKernel</a> {</div><div class="line"><a name="l00114"></a><span class="lineno">  114</span>&#160; <span class="keyword">protected</span>:</div><div class="line"><a name="l00115"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a6b23a26618db540bab3ea9073b798a56">  115</a></span>&#160;  <span class="keyword">typedef</span> BroadcastTrait <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a6b23a26618db540bab3ea9073b798a56">broadcast_type</a>;</div><div class="line"><a name="l00116"></a><span class="lineno">  116</span>&#160;</div><div class="line"><a name="l00117"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a5e501927ce96138fa54117f613657a7a">  117</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a5e501927ce96138fa54117f613657a7a">BinaryElementwise</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel.html">CudaKernel</a>(info) {}</div><div class="line"><a name="l00118"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a63654a27650f1b9d96d6b97d40c8ba54">  118</a></span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a63654a27650f1b9d96d6b97d40c8ba54">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>*)<span class="keyword"> const override </span>{</div><div class="line"><a name="l00119"></a><span class="lineno">  119</span>&#160;    <span class="keywordflow">return</span> <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a>(<a class="code" href="namespaceonnxruntime_1_1common.html#afab40a94a5b6b651a1c24921d4e5c4d5a553a760b1723d320685acd762bfd7372">common::ONNXRUNTIME</a>, <a class="code" href="namespaceonnxruntime_1_1common.html#a9dd72ac7df927aa93801eceb7e06fd2ba8c06735b7a9475ff93c7bc2e41e62f93">common::FAIL</a>);  <span class="comment">// should not reach here</span></div><div class="line"><a name="l00120"></a><span class="lineno">  120</span>&#160;  }</div><div class="line"><a name="l00121"></a><span class="lineno">  121</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#ab910a5bedfd2fe53ef82d618bf76c6bb">Prepare</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context, <span class="keywordtype">int</span> device_id, <a class="code" href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html">BinaryElementwisePreparation</a>* p) <span class="keyword">const</span>;</div><div class="line"><a name="l00122"></a><span class="lineno">  122</span>&#160;};</div><div class="line"><a name="l00123"></a><span class="lineno">  123</span>&#160;</div><div class="line"><a name="l00124"></a><span class="lineno">  124</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00125"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Add.html">  125</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Add.html">Add</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00126"></a><span class="lineno">  126</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00127"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Add.html#a5c0ce6b01c90cff092e81f67b9a5155d">  127</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Add.html#a5c0ce6b01c90cff092e81f67b9a5155d">Add</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00128"></a><span class="lineno">  128</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Add.html#a34f68019a69cf99cbc2bf9adf96cbbe6">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00129"></a><span class="lineno">  129</span>&#160;};</div><div class="line"><a name="l00130"></a><span class="lineno">  130</span>&#160;</div><div class="line"><a name="l00131"></a><span class="lineno">  131</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00132"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Sub.html">  132</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Sub.html">Sub</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00133"></a><span class="lineno">  133</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00134"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Sub.html#aeb2e4f58f734a8c5757e8af43150186d">  134</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Sub.html#aeb2e4f58f734a8c5757e8af43150186d">Sub</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00135"></a><span class="lineno">  135</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Sub.html#aeb5dd41089760e5498a11583933a7976">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00136"></a><span class="lineno">  136</span>&#160;};</div><div class="line"><a name="l00137"></a><span class="lineno">  137</span>&#160;</div><div class="line"><a name="l00138"></a><span class="lineno">  138</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00139"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Mul.html">  139</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Mul.html">Mul</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00140"></a><span class="lineno">  140</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00141"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Mul.html#a614a5f6e97cc1993a388d9cc6f487fe4">  141</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Mul.html#a614a5f6e97cc1993a388d9cc6f487fe4">Mul</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00142"></a><span class="lineno">  142</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Mul.html#acad0d0361e14828dec11252cbd07fead">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00143"></a><span class="lineno">  143</span>&#160;};</div><div class="line"><a name="l00144"></a><span class="lineno">  144</span>&#160;</div><div class="line"><a name="l00145"></a><span class="lineno">  145</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00146"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Div.html">  146</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Div.html">Div</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00147"></a><span class="lineno">  147</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00148"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Div.html#a215ff461121f42eb3ab5e12d388e7ca5">  148</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Div.html#a215ff461121f42eb3ab5e12d388e7ca5">Div</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00149"></a><span class="lineno">  149</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Div.html#af4080aced91c8ce3ce2e9a31f08b4f05">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00150"></a><span class="lineno">  150</span>&#160;};</div><div class="line"><a name="l00151"></a><span class="lineno">  151</span>&#160;</div><div class="line"><a name="l00152"></a><span class="lineno">  152</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00153"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Pow.html">  153</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Pow.html">Pow</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00154"></a><span class="lineno">  154</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00155"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Pow.html#a2ea3065f85f275a6b4bcc4eb2bffafc0">  155</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Pow.html#a2ea3065f85f275a6b4bcc4eb2bffafc0">Pow</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00156"></a><span class="lineno">  156</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Pow.html#a8d0954d35262ed182961ca491c4ffee7">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00157"></a><span class="lineno">  157</span>&#160;};</div><div class="line"><a name="l00158"></a><span class="lineno">  158</span>&#160;</div><div class="line"><a name="l00159"></a><span class="lineno">  159</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00160"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1And.html">  160</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1And.html">And</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00161"></a><span class="lineno">  161</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00162"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1And.html#af4e06a52ef1482e742562376089ffc74">  162</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1And.html#af4e06a52ef1482e742562376089ffc74">And</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00163"></a><span class="lineno">  163</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1And.html#a691b266d0442b0d513fe433c2e0c04d8">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00164"></a><span class="lineno">  164</span>&#160;};</div><div class="line"><a name="l00165"></a><span class="lineno">  165</span>&#160;</div><div class="line"><a name="l00166"></a><span class="lineno">  166</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00167"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Or.html">  167</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Or.html">Or</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00168"></a><span class="lineno">  168</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00169"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Or.html#ac5520a8de29a9f3530fdb30fbf510061">  169</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Or.html#ac5520a8de29a9f3530fdb30fbf510061">Or</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00170"></a><span class="lineno">  170</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Or.html#ad39062a46531e065f5e124e60f45baa8">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00171"></a><span class="lineno">  171</span>&#160;};</div><div class="line"><a name="l00172"></a><span class="lineno">  172</span>&#160;</div><div class="line"><a name="l00173"></a><span class="lineno">  173</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00174"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Xor.html">  174</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Xor.html">Xor</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00175"></a><span class="lineno">  175</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00176"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Xor.html#a416bbdc40e32911c3a6483ceadfbcdb9">  176</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Xor.html#a416bbdc40e32911c3a6483ceadfbcdb9">Xor</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {}</div><div class="line"><a name="l00177"></a><span class="lineno">  177</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Xor.html#ab631fd2ac34805590ed062a4dfea8bdc">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00178"></a><span class="lineno">  178</span>&#160;};</div><div class="line"><a name="l00179"></a><span class="lineno">  179</span>&#160;</div><div class="line"><a name="l00180"></a><span class="lineno">  180</span>&#160;<span class="comment">// PRelu is activation function, but it&#39;s closer to binary elementwise ops in implementation</span></div><div class="line"><a name="l00181"></a><span class="lineno">  181</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00182"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1PRelu.html">  182</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1PRelu.html">PRelu</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>&lt;ShouldBroadcast&gt; {</div><div class="line"><a name="l00183"></a><span class="lineno">  183</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00184"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1PRelu.html#af97b93e2f854fd51833f6cddb1fe7385">  184</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1PRelu.html#af97b93e2f854fd51833f6cddb1fe7385">PRelu</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">BinaryElementwise</a>(info) {</div><div class="line"><a name="l00185"></a><span class="lineno">  185</span>&#160;  }</div><div class="line"><a name="l00186"></a><span class="lineno">  186</span>&#160;</div><div class="line"><a name="l00187"></a><span class="lineno">  187</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1PRelu.html#ac22e96f904703a1dd13dc6748a67f2ae">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00188"></a><span class="lineno">  188</span>&#160;};</div><div class="line"><a name="l00189"></a><span class="lineno">  189</span>&#160;</div><div class="line"><a name="l00190"></a><span class="lineno">  190</span>&#160;<span class="comment">// Sum allows varadic inputs, and it uses binary elementwise Add in implementation</span></div><div class="line"><a name="l00191"></a><span class="lineno">  191</span>&#160;<span class="keyword">template</span> &lt;<span class="keyword">typename</span> T&gt;</div><div class="line"><a name="l00192"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Sum.html">  192</a></span>&#160;<span class="keyword">class </span><a class="code" href="classonnxruntime_1_1cuda_1_1Sum.html">Sum</a> final : <span class="keyword">public</span> <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel.html">CudaKernel</a> {</div><div class="line"><a name="l00193"></a><span class="lineno">  193</span>&#160; <span class="keyword">public</span>:</div><div class="line"><a name="l00194"></a><span class="lineno"><a class="line" href="classonnxruntime_1_1cuda_1_1Sum.html#a728700842574fe54ce95a3a7983da30a">  194</a></span>&#160;  <a class="code" href="classonnxruntime_1_1cuda_1_1Sum.html#a728700842574fe54ce95a3a7983da30a">Sum</a>(<span class="keyword">const</span> <a class="code" href="classonnxruntime_1_1OpKernelInfo.html">OpKernelInfo</a>&amp; info) : <a class="code" href="classonnxruntime_1_1cuda_1_1CudaKernel.html">CudaKernel</a>(info) {</div><div class="line"><a name="l00195"></a><span class="lineno">  195</span>&#160;  }</div><div class="line"><a name="l00196"></a><span class="lineno">  196</span>&#160;</div><div class="line"><a name="l00197"></a><span class="lineno">  197</span>&#160;  <a class="code" href="classonnxruntime_1_1common_1_1Status.html">Status</a> <a class="code" href="classonnxruntime_1_1cuda_1_1Sum.html#a07a1e4385aad90a558f83fc7abf5e93b">ComputeInternal</a>(<a class="code" href="classonnxruntime_1_1OpKernelContext.html">OpKernelContext</a>* context) <span class="keyword">const override</span>;</div><div class="line"><a name="l00198"></a><span class="lineno">  198</span>&#160;};</div><div class="line"><a name="l00199"></a><span class="lineno">  199</span>&#160;</div><div class="line"><a name="l00200"></a><span class="lineno">  200</span>&#160;}  <span class="comment">// namespace cuda</span></div><div class="line"><a name="l00201"></a><span class="lineno">  201</span>&#160;}  <span class="comment">// namespace onnxruntime</span></div><div class="ttc" id="classonnxruntime_1_1cuda_1_1And_html_a691b266d0442b0d513fe433c2e0c04d8"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1And.html#a691b266d0442b0d513fe433c2e0c04d8">onnxruntime::cuda::And::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html">onnxruntime::cuda::BinaryElementwisePreparation</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:13</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Pow_html_a2ea3065f85f275a6b4bcc4eb2bffafc0"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Pow.html#a2ea3065f85f275a6b4bcc4eb2bffafc0">onnxruntime::cuda::Pow::Pow</a></div><div class="ttdeci">Pow(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:155</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Sum_html_a728700842574fe54ce95a3a7983da30a"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Sum.html#a728700842574fe54ce95a3a7983da30a">onnxruntime::cuda::Sum::Sum</a></div><div class="ttdeci">Sum(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:194</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Or_html_ad39062a46531e065f5e124e60f45baa8"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Or.html#ad39062a46531e065f5e124e60f45baa8">onnxruntime::cuda::Or::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1TensorShape_html_a01f6e6fbc270702141c4c45573667cd5"><div class="ttname"><a href="classonnxruntime_1_1TensorShape.html#a01f6e6fbc270702141c4c45573667cd5">onnxruntime::TensorShape::Size</a></div><div class="ttdeci">int64_t Size() const</div><div class="ttdef"><b>Definition:</b> tensor_shape.cc:31</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_a36f2903469519a3db28a5138e610d2a0"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a36f2903469519a3db28a5138e610d2a0">onnxruntime::cuda::BinaryElementwisePreparation::BinaryElementwisePreparation</a></div><div class="ttdeci">BinaryElementwisePreparation(const CudaKernel *op_kernel)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:26</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Add_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Add.html">onnxruntime::cuda::Add</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:125</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1cuda_html_aa9f83573eddf1eee5577bb1c6aaae920a60212413510a410bf5192f109ecc4815"><div class="ttname"><a href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920a60212413510a410bf5192f109ecc4815">onnxruntime::cuda::SimpleBroadcast::NoBroadcast</a></div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Div_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Div.html">onnxruntime::cuda::Div</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:146</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Sum_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Sum.html">onnxruntime::cuda::Sum</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:192</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Xor_html_ab631fd2ac34805590ed062a4dfea8bdc"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Xor.html#ab631fd2ac34805590ed062a4dfea8bdc">onnxruntime::cuda::Xor::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1BinaryElementwise_html_a63654a27650f1b9d96d6b97d40c8ba54"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a63654a27650f1b9d96d6b97d40c8ba54">onnxruntime::cuda::BinaryElementwise::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *) const override</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:118</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Sum_html_a07a1e4385aad90a558f83fc7abf5e93b"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Sum.html#a07a1e4385aad90a558f83fc7abf5e93b">onnxruntime::cuda::Sum::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.cc:190</div></div>
<div class="ttc" id="classonnxruntime_1_1TensorShape_html"><div class="ttname"><a href="classonnxruntime_1_1TensorShape.html">onnxruntime::TensorShape</a></div><div class="ttdef"><b>Definition:</b> tensor_shape.h:23</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_aa0b44414b24d61109e896fb3817c4142"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#aa0b44414b24d61109e896fb3817c4142">onnxruntime::cuda::BinaryElementwisePreparation::BinaryElementwiseBroadcastPrepareHelper</a></div><div class="ttdeci">Status BinaryElementwiseBroadcastPrepareHelper(int device_id, const TensorShape &amp;lhs_shape, const TensorShape &amp;rhs_shape, const TensorShape &amp;output_shape)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:37</div></div>
<div class="ttc" id="classonnxruntime_1_1TensorShape_html_a37834c200e4b93c78a836db93d9aaa5a"><div class="ttname"><a href="classonnxruntime_1_1TensorShape.html#a37834c200e4b93c78a836db93d9aaa5a">onnxruntime::TensorShape::GetDims</a></div><div class="ttdeci">const std::vector&lt; int64_t &gt; &amp; GetDims() const</div><div class="ttdef"><b>Definition:</b> tensor_shape.h:76</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1fast__divmod_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1fast__divmod.html">onnxruntime::cuda::fast_divmod</a></div><div class="ttdef"><b>Definition:</b> fast_divmod.h:23</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1BinaryElementwise_html_a5e501927ce96138fa54117f613657a7a"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a5e501927ce96138fa54117f613657a7a">onnxruntime::cuda::BinaryElementwise::BinaryElementwise</a></div><div class="ttdeci">BinaryElementwise(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:117</div></div>
<div class="ttc" id="classonnxruntime_1_1common_1_1Status_html_aa38cc1876df38fa258f7ce916cc8cdb7"><div class="ttname"><a href="classonnxruntime_1_1common_1_1Status.html#aa38cc1876df38fa258f7ce916cc8cdb7">onnxruntime::common::Status::OK</a></div><div class="ttdeci">static const Status &amp; OK() noexcept</div><div class="ttdef"><b>Definition:</b> status.cc:69</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1PRelu_html_ac22e96f904703a1dd13dc6748a67f2ae"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1PRelu.html#ac22e96f904703a1dd13dc6748a67f2ae">onnxruntime::cuda::PRelu::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Or_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Or.html">onnxruntime::cuda::Or</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:167</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer_html_a5d0e11c43d1ab7929d7b2f32bc24871c"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a5d0e11c43d1ab7929d7b2f32bc24871c">onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CpuPtr</a></div><div class="ttdeci">T * CpuPtr() const</div><div class="ttdef"><b>Definition:</b> cuda_common.h:98</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_ae8057fc5747b8c08a40df19422ca41b0"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae8057fc5747b8c08a40df19422ca41b0">onnxruntime::cuda::BinaryElementwisePreparation::CopyToGpu</a></div><div class="ttdeci">Status CopyToGpu()</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:30</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1CudaKernel_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1CudaKernel.html">onnxruntime::cuda::CudaKernel</a></div><div class="ttdef"><b>Definition:</b> cuda_common.h:28</div></div>
<div class="ttc" id="namespaceonnxruntime_html"><div class="ttname"><a href="namespaceonnxruntime.html">onnxruntime</a></div><div class="ttdef"><b>Definition:</b> code_location.h:10</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Add_html_a5c0ce6b01c90cff092e81f67b9a5155d"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Add.html#a5c0ce6b01c90cff092e81f67b9a5155d">onnxruntime::cuda::Add::Add</a></div><div class="ttdeci">Add(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:127</div></div>
<div class="ttc" id="classonnxruntime_1_1OpKernelContext_html"><div class="ttname"><a href="classonnxruntime_1_1OpKernelContext.html">onnxruntime::OpKernelContext</a></div><div class="ttdef"><b>Definition:</b> op_kernel.h:60</div></div>
<div class="ttc" id="fast__divmod_8h_html"><div class="ttname"><a href="fast__divmod_8h.html">fast_divmod.h</a></div></div>
<div class="ttc" id="providers_2cpu_2tensor_2utils_8h_html"><div class="ttname"><a href="providers_2cpu_2tensor_2utils_8h.html">utils.h</a></div></div>
<div class="ttc" id="classonnxruntime_1_1common_1_1Status_html"><div class="ttname"><a href="classonnxruntime_1_1common_1_1Status.html">onnxruntime::common::Status</a></div><div class="ttdef"><b>Definition:</b> status.h:38</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer_html_a1719d3e411ca256e4b57898795ef58ca"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a1719d3e411ca256e4b57898795ef58ca">onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CpuSpan</a></div><div class="ttdeci">gsl::span&lt; T &gt; CpuSpan() const</div><div class="ttdef"><b>Definition:</b> cuda_common.h:102</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1common_html_a9dd72ac7df927aa93801eceb7e06fd2ba8c06735b7a9475ff93c7bc2e41e62f93"><div class="ttname"><a href="namespaceonnxruntime_1_1common.html#a9dd72ac7df927aa93801eceb7e06fd2ba8c06735b7a9475ff93c7bc2e41e62f93">onnxruntime::common::FAIL</a></div><div class="ttdef"><b>Definition:</b> status.h:24</div></div>
<div class="ttc" id="classonnxruntime_1_1Tensor_html"><div class="ttname"><a href="classonnxruntime_1_1Tensor.html">onnxruntime::Tensor</a></div><div class="ttdef"><b>Definition:</b> tensor.h:58</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Sub_html_aeb5dd41089760e5498a11583933a7976"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Sub.html#aeb5dd41089760e5498a11583933a7976">onnxruntime::cuda::Sub::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1ShouldNotBroadcast_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1ShouldNotBroadcast.html">onnxruntime::cuda::ShouldNotBroadcast</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:109</div></div>
<div class="ttc" id="structonnxruntime_1_1TensorPitches_html_a406e89348dd83badf0483bfd9df832a7"><div class="ttname"><a href="structonnxruntime_1_1TensorPitches.html#a406e89348dd83badf0483bfd9df832a7">onnxruntime::TensorPitches::Calculate</a></div><div class="ttdeci">static bool Calculate(gsl::span&lt; int64_t &gt; p, const std::vector&lt; int64_t &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> utils.h:16</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1cuda_html_aa9f83573eddf1eee5577bb1c6aaae920a2121638796bb7e7f58ffecfb894c7135"><div class="ttname"><a href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920a2121638796bb7e7f58ffecfb894c7135">onnxruntime::cuda::SimpleBroadcast::LeftScalar</a></div></div>
<div class="ttc" id="namespaceonnxruntime_1_1cuda_html_aa9f83573eddf1eee5577bb1c6aaae920ab907e3ea1ad58d2a08b02de5e8a27131"><div class="ttname"><a href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920ab907e3ea1ad58d2a08b02de5e8a27131">onnxruntime::cuda::SimpleBroadcast::RightPerChannelBatchN</a></div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1And_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1And.html">onnxruntime::cuda::And</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:160</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1PRelu_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1PRelu.html">onnxruntime::cuda::PRelu</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:182</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Xor_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Xor.html">onnxruntime::cuda::Xor</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:174</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1ShouldBroadcast_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1ShouldBroadcast.html">onnxruntime::cuda::ShouldBroadcast</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:106</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Mul_html_acad0d0361e14828dec11252cbd07fead"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Mul.html#acad0d0361e14828dec11252cbd07fead">onnxruntime::cuda::Mul::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1OpKernelInfo_html"><div class="ttname"><a href="classonnxruntime_1_1OpKernelInfo.html">onnxruntime::OpKernelInfo</a></div><div class="ttdef"><b>Definition:</b> op_kernel_info.h:23</div></div>
<div class="ttc" id="include_2onnxruntime_2core_2common_2common_8h_html_a4488572bf87ef9ee844a9aafbc35d8e4"><div class="ttname"><a href="include_2onnxruntime_2core_2common_2common_8h.html#a4488572bf87ef9ee844a9aafbc35d8e4">ONNXRUNTIME_RETURN_IF_ERROR</a></div><div class="ttdeci">#define ONNXRUNTIME_RETURN_IF_ERROR(expr)</div><div class="ttdef"><b>Definition:</b> common.h:137</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Add_html_a34f68019a69cf99cbc2bf9adf96cbbe6"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Add.html#a34f68019a69cf99cbc2bf9adf96cbbe6">onnxruntime::cuda::Add::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Div_html_a215ff461121f42eb3ab5e12d388e7ca5"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Div.html#a215ff461121f42eb3ab5e12d388e7ca5">onnxruntime::cuda::Div::Div</a></div><div class="ttdeci">Div(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:148</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Xor_html_a416bbdc40e32911c3a6483ceadfbcdb9"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Xor.html#a416bbdc40e32911c3a6483ceadfbcdb9">onnxruntime::cuda::Xor::Xor</a></div><div class="ttdeci">Xor(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:176</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1BinaryElementwise_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html">onnxruntime::cuda::BinaryElementwise</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:113</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_a7abae73c49c51912d621e34ba336aef9"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a7abae73c49c51912d621e34ba336aef9">onnxruntime::cuda::BinaryElementwisePreparation::fdm_output_strides</a></div><div class="ttdeci">CudaKernel::CudaAsyncBuffer&lt; fast_divmod &gt; fdm_output_strides</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:20</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Div_html_af4080aced91c8ce3ce2e9a31f08b4f05"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Div.html#af4080aced91c8ce3ce2e9a31f08b4f05">onnxruntime::cuda::Div::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer_html_a1987dd49b4f3fc47fe8c780ce232654d"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#a1987dd49b4f3fc47fe8c780ce232654d">onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::AllocCpuPtr</a></div><div class="ttdeci">void AllocCpuPtr(int id, size_t count)</div><div class="ttdef"><b>Definition:</b> cuda_common.h:82</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1And_html_af4e06a52ef1482e742562376089ffc74"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1And.html#af4e06a52ef1482e742562376089ffc74">onnxruntime::cuda::And::And</a></div><div class="ttdeci">And(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:162</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Mul_html_a614a5f6e97cc1993a388d9cc6f487fe4"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Mul.html#a614a5f6e97cc1993a388d9cc6f487fe4">onnxruntime::cuda::Mul::Mul</a></div><div class="ttdeci">Mul(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:141</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1cuda_html_aa9f83573eddf1eee5577bb1c6aaae920af3c8c9fc27b1c282146c15e980adf190"><div class="ttname"><a href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920af3c8c9fc27b1c282146c15e980adf190">onnxruntime::cuda::SimpleBroadcast::RightPerChannelBatch1</a></div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Or_html_ac5520a8de29a9f3530fdb30fbf510061"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Or.html#ac5520a8de29a9f3530fdb30fbf510061">onnxruntime::cuda::Or::Or</a></div><div class="ttdeci">Or(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:169</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_ad4b9356d9ef8d6ce775abe0d269580b6"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad4b9356d9ef8d6ce775abe0d269580b6">onnxruntime::cuda::BinaryElementwisePreparation::rhs_padded_strides</a></div><div class="ttdeci">CudaKernel::CudaAsyncBuffer&lt; int64_t &gt; rhs_padded_strides</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:19</div></div>
<div class="ttc" id="mlasi_8h_html_a5693f8b3559ce97985de5239fdcf6006"><div class="ttname"><a href="mlasi_8h.html#a5693f8b3559ce97985de5239fdcf6006">C</a></div><div class="ttdeci">const float float * C</div><div class="ttdef"><b>Definition:</b> mlasi.h:121</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Sub_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Sub.html">onnxruntime::cuda::Sub</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:132</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_a3d6d41eac8f6f1d9d2a66262ef6abdcf"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a3d6d41eac8f6f1d9d2a66262ef6abdcf">onnxruntime::cuda::BinaryElementwisePreparation::lhs_padded_strides</a></div><div class="ttdeci">CudaKernel::CudaAsyncBuffer&lt; int64_t &gt; lhs_padded_strides</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:18</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1cuda_html_aa9f83573eddf1eee5577bb1c6aaae920ad5cf49141f858c55da2682a66aa8dde6"><div class="ttname"><a href="namespaceonnxruntime_1_1cuda.html#aa9f83573eddf1eee5577bb1c6aaae920ad5cf49141f858c55da2682a66aa8dde6">onnxruntime::cuda::SimpleBroadcast::RightScalar</a></div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_abac17f92f3658f4b478f2f534ce21d4f"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#abac17f92f3658f4b478f2f534ce21d4f">onnxruntime::cuda::BinaryElementwisePreparation::fdm_H</a></div><div class="ttdeci">fast_divmod fdm_H</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:23</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer_html_ab0d0133fc7d6d9ca6cdd01b7ea7db54d"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html#ab0d0133fc7d6d9ca6cdd01b7ea7db54d">onnxruntime::cuda::CudaKernel::CudaAsyncBuffer::CopyToGpu</a></div><div class="ttdeci">Status CopyToGpu()</div><div class="ttdef"><b>Definition:</b> cuda_common.h:89</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Sub_html_aeb2e4f58f734a8c5757e8af43150186d"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Sub.html#aeb2e4f58f734a8c5757e8af43150186d">onnxruntime::cuda::Sub::Sub</a></div><div class="ttdeci">Sub(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:134</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_ad82404e3c1e95ec44efddff36e8e886a"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ad82404e3c1e95ec44efddff36e8e886a">onnxruntime::cuda::BinaryElementwisePreparation::lhs_tensor</a></div><div class="ttdeci">const Tensor * lhs_tensor</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:14</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1CudaKernel_1_1CudaAsyncBuffer.html">onnxruntime::cuda::CudaKernel::CudaAsyncBuffer&lt; int64_t &gt;</a></div></div>
<div class="ttc" id="classonnxruntime_1_1TensorShape_html_af9e40196654d3d161544789f61415c53"><div class="ttname"><a href="classonnxruntime_1_1TensorShape.html#af9e40196654d3d161544789f61415c53">onnxruntime::TensorShape::NumDimensions</a></div><div class="ttdeci">size_t NumDimensions() const noexcept</div><div class="ttdef"><b>Definition:</b> tensor_shape.h:62</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_a30db30553236d3694eb6442c2af7edb4"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a30db30553236d3694eb6442c2af7edb4">onnxruntime::cuda::BinaryElementwisePreparation::rhs_tensor</a></div><div class="ttdeci">const Tensor * rhs_tensor</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:15</div></div>
<div class="ttc" id="classonnxruntime_1_1TensorShape_html_a4a084e4fe8348af11cf8cf1d22c4800d"><div class="ttname"><a href="classonnxruntime_1_1TensorShape.html#a4a084e4fe8348af11cf8cf1d22c4800d">onnxruntime::TensorShape::SizeFromDimension</a></div><div class="ttdeci">int64_t SizeFromDimension(size_t dimension) const</div><div class="ttdef"><b>Definition:</b> tensor_shape.cc:48</div></div>
<div class="ttc" id="cuda__common_8h_html"><div class="ttname"><a href="cuda__common_8h.html">cuda_common.h</a></div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1BinaryElementwise_html_a6b23a26618db540bab3ea9073b798a56"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#a6b23a26618db540bab3ea9073b798a56">onnxruntime::cuda::BinaryElementwise::broadcast_type</a></div><div class="ttdeci">BroadcastTrait broadcast_type</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:115</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1cuda_html_ad1695824538013a3c72989f1a78ce5ec"><div class="ttname"><a href="namespaceonnxruntime_1_1cuda.html#ad1695824538013a3c72989f1a78ce5ec">onnxruntime::cuda::CalculateFdmStrides</a></div><div class="ttdeci">bool CalculateFdmStrides(gsl::span&lt; fast_divmod &gt; p, const std::vector&lt; int64_t &gt; &amp;dims)</div><div class="ttdef"><b>Definition:</b> cuda_common.h:163</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Mul_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Mul.html">onnxruntime::cuda::Mul</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:139</div></div>
<div class="ttc" id="include_2onnxruntime_2core_2common_2common_8h_html_ad131e4f1ee9a9dcb3fe224c5eea0ffaf"><div class="ttname"><a href="include_2onnxruntime_2core_2common_2common_8h.html#ad131e4f1ee9a9dcb3fe224c5eea0ffaf">ONNXRUNTIME_RETURN_IF_NOT</a></div><div class="ttdeci">#define ONNXRUNTIME_RETURN_IF_NOT(condition,...)</div><div class="ttdef"><b>Definition:</b> common.h:112</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1PRelu_html_af97b93e2f854fd51833f6cddb1fe7385"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1PRelu.html#af97b93e2f854fd51833f6cddb1fe7385">onnxruntime::cuda::PRelu::PRelu</a></div><div class="ttdeci">PRelu(const OpKernelInfo &amp;info)</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:184</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_a8e5baa8a6c92e84c17e3e040ca9acdd2"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#a8e5baa8a6c92e84c17e3e040ca9acdd2">onnxruntime::cuda::BinaryElementwisePreparation::output_tensor</a></div><div class="ttdeci">Tensor * output_tensor</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:16</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1BinaryElementwise_html_ab910a5bedfd2fe53ef82d618bf76c6bb"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1BinaryElementwise.html#ab910a5bedfd2fe53ef82d618bf76c6bb">onnxruntime::cuda::BinaryElementwise::Prepare</a></div><div class="ttdeci">Status Prepare(OpKernelContext *context, int device_id, BinaryElementwisePreparation *p) const</div></div>
<div class="ttc" id="namespaceonnxruntime_1_1common_html_afab40a94a5b6b651a1c24921d4e5c4d5a553a760b1723d320685acd762bfd7372"><div class="ttname"><a href="namespaceonnxruntime_1_1common.html#afab40a94a5b6b651a1c24921d4e5c4d5a553a760b1723d320685acd762bfd7372">onnxruntime::common::ONNXRUNTIME</a></div><div class="ttdef"><b>Definition:</b> status.h:16</div></div>
<div class="ttc" id="classonnxruntime_1_1TensorShape_html_af322918934d44918346fe19526f52897"><div class="ttname"><a href="classonnxruntime_1_1TensorShape.html#af322918934d44918346fe19526f52897">onnxruntime::TensorShape::SizeToDimension</a></div><div class="ttdeci">int64_t SizeToDimension(size_t dimension) const</div><div class="ttdef"><b>Definition:</b> tensor_shape.cc:38</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Pow_html_a8d0954d35262ed182961ca491c4ffee7"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Pow.html#a8d0954d35262ed182961ca491c4ffee7">onnxruntime::cuda::Pow::ComputeInternal</a></div><div class="ttdeci">Status ComputeInternal(OpKernelContext *context) const override</div></div>
<div class="ttc" id="classonnxruntime_1_1cuda_1_1Pow_html"><div class="ttname"><a href="classonnxruntime_1_1cuda_1_1Pow.html">onnxruntime::cuda::Pow</a></div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:153</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_ae6b234b7debc4cba40d21bbff24c18e6"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ae6b234b7debc4cba40d21bbff24c18e6">onnxruntime::cuda::BinaryElementwisePreparation::output_rank_or_simple_broadcast</a></div><div class="ttdeci">size_t output_rank_or_simple_broadcast</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:17</div></div>
<div class="ttc" id="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation_html_ac07a5b9eca61fcc7295038038d306cda"><div class="ttname"><a href="structonnxruntime_1_1cuda_1_1BinaryElementwisePreparation.html#ac07a5b9eca61fcc7295038038d306cda">onnxruntime::cuda::BinaryElementwisePreparation::fdm_C</a></div><div class="ttdeci">fast_divmod fdm_C</div><div class="ttdef"><b>Definition:</b> binary_elementwise_ops.h:24</div></div>
</div><!-- fragment --></div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.14
</small></address>
</body>
</html>
