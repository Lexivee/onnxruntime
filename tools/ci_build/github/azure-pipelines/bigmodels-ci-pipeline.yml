# reference: https://github.com/microsoft/onnxruntime/blob/main/onnxruntime/python/tools/transformers/models/stable_diffusion/README.md
stages:
- stage: Stale_Diffusion
  jobs:
  - job: Stale_Diffusion
    variables:
      skipComponentGovernanceDetection: true
      CCACHE_DIR: $(Pipeline.Workspace)/ccache
    workspace:
      clean: all
    pool: onnxruntime-Linux-GPU-A10-16G
    steps:
    - task: mspremier.PostBuildCleanup.PostBuildCleanup-task.PostBuildCleanup@3
      displayName: 'Clean Agent Directories'
      condition: always()

    - checkout: self
      clean: true
      submodules: none

    - task: Cache@2
      inputs:
        key: '"ccache" | "$(Build.SourceBranch)" | "$(Build.SourceVersion)"'
        path: $(CCACHE_DIR)
        restoreKeys: |
          "ccache" | "$(Build.SourceBranch)"
          "ccache"
        cacheHitVar: CACHE_RESTORED
      displayName: Cach Task

    - script: |
        sudo mkdir -p $(Pipeline.Workspace)/ccache
      condition: ne(variables.CACHE_RESTORED, 'true')
      displayName: Create Cache Dir

    - script: |
        docker run --rm --gpus all -v $PWD:/workspace -e CCACHE_DIR=/cache \
          nvcr.io/nvidia/pytorch:23.10-py3 \
          bash -c "
            set -ex; \
            export CUDACXX=/usr/local/cuda-12.2/bin/nvcc; \
            git config --global --add safe.directory '*'; \
            sh build.sh --config Release  --build_shared_lib --parallel --use_cuda --cuda_version 12.2 \
                        --cuda_home /usr/local/cuda-12.2 --cudnn_home /usr/lib/x86_64-linux-gnu/ --build_wheel --skip_tests \
                        --use_tensorrt --tensorrt_home /usr/src/tensorrt \
                        --cmake_extra_defines onnxruntime_BUILD_UNIT_TESTS=OFF \
                        --cmake_extra_defines CMAKE_CUDA_ARCHITECTURES=86 \
                        --allow_running_as_root; \
                        --use_cache; \
          "
      displayName: 'Build Onnxruntime'
      workingDirectory: $(Build.SourcesDirectory)

    - script: |
        docker run --rm --gpus all -v $PWD:/workspace nvcr.io/nvidia/pytorch:23.10-py3 \
          bash -c "
            set -ex; \
            python3 -m pip install --upgrade pip; \
            python3 -m pip install build/Linux/Release/dist/*.whl; \
            pushd /workspace/onnxruntime/python/tools/transformers/models/stable_diffusion; \
            python3 -m pip install -r requirements-cuda12.txt; \
            python3 -m pip install --upgrade polygraphy onnx-graphsurgeon --extra-index-url https://pypi.ngc.nvidia.com; \
            echo Generate an image guided by a text prompt; \
            python3 demo_txt2img.py "astronaut riding a horse on mars"; \
            echo Generate an image with Stable Diffusion XL guided by a text prompt; \
            python3 demo_txt2img_xl.py 'starry night over Golden Gate Bridge by van gogh'; \
            python3 demo_txt2img_xl.py --enable-refiner 'starry night over Golden Gate Bridge by van gogh'; \
            echo Generate an image guided by a text prompt using LCM LoRA; \
            python3 demo_txt2img_xl.py --scheduler LCM --lora-weights latent-consistency/lcm-lora-sdxl --denoising-steps 4 "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k"; \
            popd; \
          "
      displayName: 'Run stable diffusion demo'
      workingDirectory: $(Build.SourcesDirectory)
