trigger: none

jobs:
- job: Onnxruntime_Linux_Nightly_GPU_OnDeviceTraining

  timeoutInMinutes: 120
  pool: 'Onnxruntime-Linux-GPU-NC6sv3'

  steps:
  - checkout: self
    clean: true
    submodules: recursive

  - template: templates/run-docker-build-steps.yml
    parameters:
      RunDockerBuildArgs: |
        -o nightly-ubuntu2004-cu113-py38-torch1130dev:latest -d gpu -e \
        -t onnxruntime_ondevicetraining_nightly_tests_image \
        -x " \
          --config RelWithDebInfo \
          --enable_training \
          --enable_training_on_device \
          --use_cuda --cuda_version=11.3 --cuda_home=/usr/local/cuda-11.3 --cudnn_home=/usr/local/cuda-11.3 \
          --build_wheel \
          --skip_tests \
          " \
        -u
      DockerImageTag: 'onnxruntime_ondevicetraining_nightly_tests_image'
      DisplayName: 'Build onnxruntime'

  # Entry point for all on device training tests
  - script: |
      docker run \
        --gpus all \
        --shm-size=1024m \
        --rm \
        --volume $(Build.SourcesDirectory):/onnxruntime_src \
        --volume $(Build.BinariesDirectory):/build \
        onnxruntime_ondevicetraining_nightly_tests_image \
          /build/RelWithDebInfo/launch_test.py \
            --cwd /build/RelWithDebInfo --cmd_line_with_args "python3 -m pip install -r /onnxruntime_src/tools/ci_build/github/linux/docker/scripts/training/ortmodule/stage1/requirements_torch_nightly/requirements.txt && python orttraining_on_device_training_tests.py --cwd /build/RelWithDebInfo" \
    displayName: 'Run On-Device Training Tests'
    condition: succeededOrFailed()
    timeoutInMinutes: 120
  - template: templates/component-governance-component-detection-steps.yml
    parameters:
      condition: 'succeeded'

  - template: templates/clean-agent-build-directory-step.yml
